\chapter{Statistical Interpretation}\label{Sec:Stat}

Before we can understand the final results of this analysis, we must consider the error analysis. This involves accounting for errors related to data, signal MC, tt MC, and the background estimation method. We must also consider how to interpret the results of our background estimation. 

\section{Systematic uncertainties\label{sec:Systematics}}

There are several systematic uncertainty affect the expected signal and tt efficiencies in this analysis, itemized below. The background estimation of QCD is unaffected by them because it is computed entirely from data, which brings with it different procedural sources of systematic uncertainty as described in the following text. We first present the uncertainties that impact the normalization of the signal and tt, followed by those which impact the background estimate.

\begin{itemize}

\item \textbf{Luminosity}: An uncertainty of 2.5\%~\cite{CMS-PAS-LUM-17-001} is applied to account for the uncertainty in the total luminosity in this dataset. This uncertainty is treated as an overall normalization uncertainty.

\item \textbf{Pileup}: Each event is reweighted as a function of the number of primary vertices in the event in order to mimic the amount of pileup based off of what is observed in data. An uncertainty up to 5\% for signal and 1\% for tt is associated with pileup impact on $M_{jjj}^{red}$ by varying the estimated minimum bias cross section of pp collisions at 13 TeV (= 69.2 mb) by $\pm 4.6\%$~\cite{PileupTWiki}. This uncertainty is treated as an overall normalization uncertainty.

\item \textbf{PDF and scale hypotheses impact}: The impact of the signal acceptance due to the uncertainties on the PDF is estimated to be up to 0.7\% in the simulated samples used, depending on the resonance mass. For tt, we also consider this uncertainty, which is less than 2\%.

\item \textbf{tt Cross Section Uncertainty}: The total uncertainty, calculated as the sum in quadrature of the scale uncertainty and the PDF+alphaS uncertainty on the cross section of tt is applied, amounting to 6\%, as prescribed by the TOP PAG group: Cross section = 831.76 +19.77-29.20 (scale) +35.06-35.06 (PDF+alpha s) pb. 

\item \textbf{Trigger efficiency uncertainty}: The trigger strategy is described in Chapter~\ref{Sec:Ana}. We have evaluated the trigger scale factor (SF) using JetHT and QCD HT-binned MC samples. We assign an uncertainty since the baseline trigger \texttt{HLT\_PFJet260} too has inefficiency in the turn-on region, but this cannot be measured definitively in the data. This is measured in the Monte Carlo against offline event selection that is close to the final signal region selection. There is also an additional uncertainty due to the difference in flavour composition of the QCD sample in comparison with signal samples, since one of the triggers uses a b-tagging requirement. The scale factors with these uncertainties are applied to the signal and tt MC as a function of $M_{jjj}^{red}$. This trigger uncertainty is treated as a shape-based uncertainty, which means that both the difference in shape and normalization are taken into account.
%For $\Mjjs > 1100\GeV$ the trigger efficiency is $\ge 99\%$ with negligible uncertainty. For $\Mjjs < 1100\GeV$ the trigger efficiency is between 60--99\% and has a dependence on the $\Delta\eta(j1,j2)$ as shown in Figs.~\ref{fig:trigeEffvsMjj_JetHT_DetaBins} and \ref{fig:trigeEffvsMjj_QCDHT_HLTPFJet260_DEtabins}. Thus, below the turn-on region, we have evaluated the trigger scale factor using JetHT and QCD HT-binned MC samples. An additional uncertainty is applied to the SF, as stated above. We have also decided to evaluate the trigger efficiency scale factor in three bins of $\Delta\eta(j1,j2)$. We then assign an additional uncertainty since the baseline trigger \texttt{HLT\_PFJet260} too has inefficiency in the turn-on region, but this cannot be measured definitively in the data. This is measured in the Monte Carlo against offline event selection that is close to the final signal region selection. The scale factors with these uncertainties, as shown in Fig.~\ref{fig:trigeEffSFvsMjj_JetHT_DetaBins}, are applied to the signal MC.
  
\item \textbf{Double-b-tagging and Deep CSV b-tagging}: Scale factors for the double-b and deep CSV tagger are computed in an enriched gluon splitting to bb data sample. These two quantities are considered correlated since the samples used to measure the SFs are similar, and the taggers use similar inputs. Details on the derivation of these SF are provided in Ref.~\cite{DoubleBSFTWiki}. The corresponding uncertainty is about 3-9\% per event. The mistag SFs are applied to tt, corresponding to an uncertainty of 13\%.

%\item \textbf{DeepCSV b-tagging}: Scale factors for the deep CSV tagger have a corresponding uncertainty of about 3-5\% per event for signal, and 7\% for tt. The double-b tagger uncertainty and the deepCSV uncertainty are taken to be 100\% correlated.

\item \textbf{$\tau_{21}$ scale factor}: The scale factor for $\tau_{21}$ selection is measured using semi-leptonic tt sample that is a generous source of boosted hadronic W bosons~\cite{CMS-AN-17-051}. We correct the signal and tt yield by the SF as recommended from the POG~\cite{Wtagging}: SF$(\tau_{21} < 0.55) = 1.03 \pm 0.14$ for each jet. Additional uncertainty due to the difference between Higgs jets and W jets are determined as described below.
  
\item \textbf{Higgs Tagging}: Similar to the $\tau_{21}$ scale factor uncertainty above, the jet mass correction is also evaluated using W jets in semileptonic tt+jets events, amounting to $1 \pm 0.0094$. A jet mass resolution scale factor of $1 \pm 0.20$ is also obtained using the above measurement. These are propagated to the Higgs-tagged jets along with the uncertainties for signal.
The main differences between the Higgs jets and W jets are the different mass scales and jet flavour compositions, leading to a different shower profile in the jets. The procedure for measuring the scale factor to account for this for Higgs-tagged signal jets is described in~\cite{CMS-PAS-B2G-16-026}.
%There is no way to measure the scale factor for Higgs-tagged jets using the data. The main differences between the Higgs jets and $\PW$ jets are the different mass scales and jet flavour compositions, leading to a different shower profile in the jets. The efficiency ratios measured using the two parton shower+hadronization model gives a reasonable estimate on the differences between the Higgs jets and $\PW$ jets. Thus the scale factor derived for $\PW$ jets are used and a additional systematic uncertainty is applied as follows: The ratio of Higgs-tagging to the $\PW$-tagging efficiency is measured is \PYTHIA and \HERWIG samples, using samples of ${\rm bulk graviton}\to\PW\PW$ and ${\rm bulk graviton}\to\HH$. We choose a mass window for the $\PW$ and the $\PH$. Then we calculate the double ratio $R_{\HERWIG}/R_{\PYTHIA}$ of efficiency ratio. The double ratio provides an estimate of how different showering algorithms handle the difference between hadronically decaying $\PW$ and $\PH$. These corresponded to uncertainties of \textcolor{red}{amount} per jet. See Table~\ref{tab:WideWindow}. There is a $\pt$ dependence of the uncertainty that is evaluated by comparing Higgs tagged jets in \PYTHIA and \HERWIG and propagated to the overall uncertainty, this is the same as that used for the VH resonance search B2G-17-002~\cite{AN-2016-377}. 
This is not applied to tt, since it has hadronically decaying W. This uncertainty corresponds to .5-8.8\% depending on signal mass.

%\begin{sidewaystable}[!htb]
%  \begin{center}
%\caption{The per-jet efficiency of requiring the mass of Higgs (W) jets to
%be within 105--135 (65--105) \GeV and $\tau_{21}<0.55$. The efficiency is evaluated with the $G_\mathrm{bulk}\rightarrow \mathrm{hh} (\mathrm{WW})$% samples.\label{tab:WideWindow}}
%  \begin{tabular}{c|rrrrrrr}
%\hline\hline
%$M_{G_\mathrm{bulk}}$ [GeV] &  $\epsilon_{\mathrm{hh}}^{\HERWIG}$ &  $\epsilon_{\mathrm{WW}}^{\HERWIG}$ & $\epsilon_{\mathrm{hh}}^{\HERWIG}/\epsilon_{\mathrm{WW}}^{\HERWIG}$
%                                         &  $\epsilon_{\mathrm{hh}}^{\PYTHIA}$ &  $\epsilon_{\mathrm{WW}}^{\PYTHIA}$ &  $\epsilon_{\mathrm{hh}}^{\PY%THIA}/\epsilon_{\mathrm{WW}}^{\PYTHIA}$ &  $R_{\HERWIG}/R_{\PYTHIA}$ \\
%\hline
%1000 & 0.379 $\pm$ 0.005 & 0.631 $\pm$ 0.008 & 0.601 $\pm$ 0.015 & 0.460 $\pm$ 0.005 & 0.668 $\pm$ 0.009 & 0.688 $\pm$ 0.017 & 0.876 $\pm$ 0.04 \\
%2000 & 0.502 $\pm$ 0.006 & 0.569 $\pm$ 0.007 & 0.715 $\pm$ 0.017 & 0.502 $\pm$ 0.006 & 0.618 $\pm$ 0.008 & 0.812 $\pm$ 0.018 & 0.881 $\pm$ 0.04 \\
%3000 & 0.387 $\pm$ 0.005 & 0.509 $\pm$ 0.012 & 0.761 $\pm$ 0.020 & 0.467 $\pm$ 0.005 & 0.568 $\pm$ 0.007 & 0.822 $\pm$ 0.015 & 0.926 $\pm$ 0.04 \\

%\hline
%\hline
%\end{tabular}
%\end{center}
%\end{sidewaystable}

\item \textbf{Jet Energy Scale}: We have accounted for .2-4\% effect on the yield for signal and up to 1\% for tt due to the jet energy correction factors which account for difference in jet energies between data and MC. %The JEC uncertainty on the signal shape is about $\pm 1\%$ on the mean and the width, as shown in Fig.~\ref{fig:singalMeanWidthChange_JECUncert}.

%\begin{figure}[h]
%\centering
%\includegraphics[width=0.4\textwidth]{F5/signalMeanChange_JECUncert}
%\includegraphics[width=0.4\textwidth]{F5/signalWidthChange_JECUncert}
%\caption{The impact of JEC uncertainty on the signal mean and width for bulk gravitons of different masses. The change in the mean is about $\pm 1\%$. The same amount is expected also for radions.}
%\label{fig:singalMeanWidthChange_JECUncert}
%\end{figure}

\item \textbf{Jet Energy Resolution}: We have accounted for up to 1.8\% effect on the yield for signal, and up to .7\% for tt, using gaussian smearing when the jet has no match to a generator level jet, as prescribed by the Jet Energy Corrections and Resolution Subgroup. This accounts for the difference in jet energy resolution between data and MC. 
%The JER uncertainty on the signal shape is negligible, and is about $\pm 1\%$ on the width, as shown in Fig.~\ref{fig:singalMeanWidthChange_JERUncert}.

%\begin{figure}[h]
%\centering
%\includegraphics[width=0.4\textwidth]{F5/signalMeanChange_JERUncert}
%\includegraphics[width=0.4\textwidth]{F5/signalWidthChange_JERUncert}
%\caption{The impact of JER uncertainty on the signal mean and width for bulk gravitons of different masses. The change in the mean is negligible, and the width is about $\pm 1\%$. The same amount is expected also for radions.}
%\label{fig:singalMeanWidthChange_JERUncert}
%\end{figure}
\item \textbf{TriAK4jet Mass Cut}: The systematic for this cut was calculated by comparing the cut efficiency for the Pythia and Herwig Bulk Graviton 1000 GeV samples and is equivalent to 0.5\% uncertainty. 

\item \textbf{Multijets background from the data}: %The main uncertainty on the main analysis background can be estimated a number of ways depending on which background estimate is being used:
%\begin{itemize}
%\item \textbf{Alphabet}: 
%We only apply these uncertainties to the estimate for $\mjjs < 1200\GeV$, which uses the Alphabet Method. 
As mentioned in the previous chapter, the main source of uncertainty for the QCD background estimate comes from the error of the fit on $R_{p/f}$ in the mass sidebands, used to determine the value of $R_{p/f}$ in the mass window . This uncertainty can be treated as a shape based uncertainty. We also account for the statistical uncertainty in the anti-tag region which is propagated to the estimated signal region.
%While this uncertainty is the dominant uncertainty in the entire estimate, it is fully correlated between all bins of a particular estimate. 
%We must further account for the statistical uncertainty in the anti-tag region which is propagated to the signal region when the estimate is made. 
%This uncertainty is small compared to the fit uncertainty, but is uncorrelated from bin to bin. 
The Barlow-Beeston Lite~\cite{BBLite} method is used to treat this bin-by-bin statistical uncertainty. 



%\item \textbf{Top \pt reweighting}: As prescribed by the top group~\cite{CMS-PAS-TOP-16-011,CMS-PAS-TOP-16-008}, tt is reweighting by the generator \pt using the following formula:
%\begin{equation}
%e^{0.0615 - 0.005(generator HT)/2)}
%\label{eq:ptreweight}
%\end{equation}
%The normalization and $\alpha$ = 0.005 are varied by 25\% and a systematic of 1.5\% for the normalization and 4.2\% for the $\alpha$ is accounted for.
%\end{itemize}
%The relative contributions of both uncertainties in the QCD closure test are shown in Section~\ref{sec:BkgEst}.

%\item \textbf{AABH}: For the remaining  phase-space in \mjjs, we use errors from the AABH method. In this case, the uncertainty in the $R_{p/f}$ ratio is used as a Gaussian constraint on the conversion from the antitag region to the Signal region. We further measure the dependence of $R_{p/f}$ on the \mjjs variable. The uncertainty in this dependence is also provided as a  Gaussian constraint. With these constraints in place, the uncertainty in the AABH background estimate is simply the uncertainty in the simultaneous fit function. As the linear dependence of $R_{p/f}$ is a parameter of the fit, uncertainty in this value is part of the overall error shapes. The datacards provided below show how these constraints are passed to combine.
%\end{itemize}

\end{itemize}


%\begin{figure}[h]
%\centering
%\includegraphics[trim={1cm 0cm 0cm 0cm},width=1.0\textwidth]{F5/HH_mX_1200_bump_13TeV.pdf}
%\caption{A datacard for the 750 GeV mass Bulk Graviton signal hypothesis. }
%\label{fig:datacard}
%\end{figure}

%\begin{figure}[h]
%\centering
%\includegraphics[width=0.4\textwidth]{covariance_fit_b_HH_mX_800_Alphabet_13TeV.png}
%\includegraphics[width=0.4\textwidth]{covariance_fit_b_HH_mX_900_Alphabet_13TeV.png}
%\includegraphics[width=0.4\textwidth]{covariance_fit_b_HH_mX_1400_bump_13TeV.png}
%\includegraphics[width=0.4\textwidth]{covariance_fit_b_HH_mX_2000_bump_13TeV.png}
%  \caption{The nuisance parameter covariance for bulk gravitons of masses 800 (upper left) and 900\GeV (upper right), with backgrounds measured using the Alphabet method. The same for bulk graviton of masses 1400 (lower left) and 2000\GeV (lower right) with backgrounds measured using the AABH method.}
%\label{fig:nuianceCovar}
%\end{figure}


%\begin{figure}[h]
%\centering
%  \includegraphics[width=0.4\textwidth]{nuisanceImpacts_HH_mX_800_Alphabet_13TeV_mu1.pdf}
%  \includegraphics[width=0.4\textwidth]{nuisanceImpacts_HH_mX_900_Alphabet_13TeV_mu1.pdf}
%  \includegraphics[width=0.4\textwidth]{nuisanceImpacts_HH_mX_1400_bump_13TeV_mu1.pdf}
%\includegraphics[width=0.4\textwidth]{nuisanceImpacts_HH_mX_2000_bump_13TeV_mu1.pdf}
%  \caption{The nuisance parameter impact for bulk gravitons of masses 800 (upper left) and 900\GeV (upper right), with backgrounds measured using t%he Alphabet method. The same for bulk graviton of masses 1400 (lower left) and 2000\GeV (lower right) with backgrounds measured using the AABH method.}
%\label{fig:nuianceImpact}
%\end{figure}

%We have also included a datacard that is used as input for the CMS Higgs Combination Tool in Figure.~\ref{fig:datacard} as an example, for Bulk Graviton mass 1000 and selection rejecting boosted events for $\Delta\eta$ 0-1. Lastly, a documentation of the nuisance parameters can be found in App.~\ref{app:background}.

%\begin{figure}[thb!]
%\begin{center}
%includegraphics[scale=0.5]{F5/datacardForNote.pdf}
%\end{center}
%\caption{Datacard for Bulk Graviton 1000 GeV rejecting boosted events for $\Delta\eta$ 0-1.}
%\label{fig:datacard}
%\end{figure} 

\section{Limit setting procedure}

There exists a difference between data and the estimated background shown in the figures in the previous chapter. We must understand how to perform this comparison in a meaningful way. In particle physics, this is most often done using confidence levels to quantify the agreement between data and a background-only hypothesis versus a background+signal hypothesis. 
We once again examine the comparison between data and the background estimation in $M_{jjj}^{red}$, as well as signal in $M_{jjj}^{red}$ in Figure~\ref{fig:databoost2}.
\begin{figure}[h]
\centering
\includegraphics[width=0.45\textwidth]{F5/HH4b2p1_Plot_NRv1_unB1_boost_dEta1.pdf}
\includegraphics[width=0.45\textwidth]{F5/HH4b2p1_Plot_NRv1_unB1_boost_dEta2.pdf}
\caption{Signal region in data for a selection rejecting boosted events.}
\label{fig:databoost2}
\end{figure}
We use the asymptotic approximation of the modified frequentist approach for confidence levels~\cite{Junk:1999kv, Read:2002hq, Conway:1333496} to determine how likely signal is to be present given the binned distribution of signal, the background estimate, and data. We define the likelihood ratio as
\begin{equation}
\mathcal{L}(n,x) = \frac{e^{-x}x^{n}}{n!}
\end{equation}
Then for each bin, we calculate the ratio of $\mathcal{L}(N_{\text{data}}, \mu N_{\text{sig}} + N_{\text{back}})$ and  $\mathcal{L}(N_{\text{data}}, N_{\text{back}})$, where $N_{\text{data}}$ is the number of data events in a given bin, $\mu$ scales the amount of signal in each bin, $N_{\text{sig}}$ is the amount of signal MC events in a given bin, and $N_{\text{back}}$ is the amount of tt MC events in a given bin added together with the amount of estimated QCD events in a given bin (calculated from the background estimation). This ratio is multiplied for each bin for a combined likelihood, and then fit to calculate $\mu$, or the amount of signal in each bin given $N_{\text{data}}$ and $N_{\text{back}}$. Both $N_{\text{sig}}$ and $N_{\text{back}}$ have nuisance parameters, described in the previous section, that cause these values to fluctuate up and down, and this is taken into account. 

The expected cross section is then calculated from a background-only hypothesis, that is to say what would be observed should no signal exist. This is compared to the observed cross section calculated by including the possibility that signal could exist, while also considering all of the systematic and statistical uncertainties that could cause the observed cross section to fluctuate up or down. This comparison, presented in the next chapter, allows us to determine whether new physics has been found, or whether some amount of phasespace in a particular model has been ruled out. 
